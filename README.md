# Cuda-ML-Pipeline-Optimization-Nsight ğŸš€  
Optimized a real-time video segmentation pipeline using **CUDA**, **TensorRT**, **CV-CUDA**, and **Nsight profiling tools** â€” achieving full GPU acceleration and reducing end-to-end runtime from **52.14s to 3.89s**.

---

## ğŸ§  Overview

This project demonstrates how to analyze and optimize a machine learning video processing pipeline using NVIDIA's profiling tools. The focus is on:

- **Profiling and identifying bottlenecks** with Nsight Systems
- **Accelerating model inference** with TensorRT
- **Moving preprocessing and postprocessing to the GPU** using CV-CUDA
- **Using NVDEC/NVENC for GPU-based video decoding and encoding**

---

## ğŸ”§ Pipeline Stages

### ğŸ”¹ 1. Decoder (NVDEC Hardware Acceleration)
- Original: OpenCV-based decoding on CPU  
- Optimized: Replaced with **NVIDIA NVDEC**, which performs decoding on GPU â€” eliminating large host-to-device memory transfers.

### ğŸ”¹ 2. Preprocessing (CV-CUDA)
- Original: OpenCV (CPU) operations like resize, normalize  
- Optimized: All pre-processing moved to GPU using **CV-CUDA** â€” boosting throughput and reducing latency.

### ğŸ”¹ 3. Inference (TensorRT)
- Original: PyTorch model executed using standard CUDA kernels  
- Optimized: Converted model to **TensorRT engine** for GPU-specific optimizations, kernel fusion, and FP16 support.

### ğŸ”¹ 4. Postprocessing (CV-CUDA)
- Applied operations like blurring directly on GPU using **CV-CUDA**, avoiding host-device syncs.

### ğŸ”¹ 5. Encoder (NVENC Hardware Acceleration)
- Original: OpenCV-based encoder  
- Optimized: Switched to **NVENC**, leveraging dedicated GPU silicon for real-time video encoding.

---

## ğŸ“ˆ Profiling & Results

### Baseline Model Profiling  
Command:
```bash
nsys profile --trace cuda,nvtx,osrt \
--output baseline \
--force-overwrite=true \
python video_segmentation/main_nvtx.py
````

**Pipeline Execution Time:** 52.142 seconds

---

### Optimized Model Profiling

Command:

```bash
nsys profile --trace cuda,nvtx,osrt \
--output optimized \
--force-overwrite=true \
python video_segmentation/main_optimized.py
```

**Pipeline Execution Time:** â±ï¸ 3.890 seconds

âœ… Achieved a **\~13.4Ã— speedup** by removing CPU-GPU bottlenecks and using GPU-native libraries throughout the pipeline.

---

## ğŸ” Tools & Technologies

* ğŸ§  **TensorRT** â€” GPU-optimized deep learning inference
* ğŸ **NVDEC / NVENC** â€” GPU-based video decoding & encoding
* ğŸ§° **CV-CUDA** â€” GPU-native image pre/post-processing
* ğŸ”¬ **Nsight Systems / Nsight Compute** â€” CUDA profiling & bottleneck analysis
* ğŸ”¥ **NVTX Markers** â€” For annotated timeline visualizations
